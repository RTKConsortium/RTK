/*=========================================================================
 *
 *  Copyright RTK Consortium
 *
 *  Licensed under the Apache License, Version 2.0 (the "License");
 *  you may not use this file except in compliance with the License.
 *  You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0.txt
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
 *
 *=========================================================================*/

#ifndef __rtkCudaUtilities_hcu
#define __rtkCudaUtilities_hcu

#ifdef _WIN32
# include <math.h>
# define __CUDA_INTERNAL_COMPILATION__
# include <math_functions.h>
# undef __CUDA_INTERNAL_COMPILATION__
#endif
#include <cuda_runtime_api.h>
#include <string>
#include <vector>
#define ITK_STATIC
#include <itkMacro.h>
#undef ITK_STATIC
#include <cuda.h>

#define CUDA_CHECK_ERROR \
    { \
    cudaError_t err = cudaGetLastError(); \
    if (cudaSuccess != err) \
      itkGenericExceptionMacro(<< "CUDA ERROR: " << cudaGetErrorString(err) << std::endl); \
    }

#define CUFFT_CHECK_ERROR(result) \
    { \
    if (result) \
      itkGenericExceptionMacro(<< "CUFFT ERROR #" << result << std::endl); \
    }

std::vector<int> GetListOfCudaDevices();
std::pair<int,int> GetCudaComputeCapability(int device);
size_t GetFreeGPUGlobalMemory(int device);

inline __host__ __device__ float3 matrix_multiply(float3 a, float* matrix)
{
    return make_float3(matrix[0] * a.x + matrix[1] * a.y + matrix[2] * a.z + matrix[3],
                       matrix[4] * a.x + matrix[5] * a.y + matrix[6] * a.z + matrix[7],
                       matrix[8] * a.x + matrix[9] * a.y + matrix[10] * a.z + matrix[11]);
}
inline __host__ __device__ float3 operator-(float3 a, float3 b)
{
    return make_float3(a.x - b.x, a.y - b.y, a.z - b.z);
}
inline __host__ __device__ float3 fminf(float3 a, float3 b)
{
  return make_float3(fminf(a.x,b.x), fminf(a.y,b.y), fminf(a.z,b.z));
}
inline __host__ __device__ float3 fmaxf(float3 a, float3 b)
{
  return make_float3(fmaxf(a.x,b.x), fmaxf(a.y,b.y), fmaxf(a.z,b.z));
}
inline __host__ __device__ float dot(float3 a, float3 b)
{
    return a.x * b.x + a.y * b.y + a.z * b.z;
}
inline __host__ __device__ float3 operator/(float3 a, float3 b)
{
    return make_float3(a.x / b.x, a.y / b.y, a.z / b.z);
}
inline __host__ __device__ float3 operator/(float3 a, float b)
{
    return make_float3(a.x / b, a.y / b, a.z / b);
}
inline __host__ __device__ float3 operator*(float3 a, float3 b)
{
    return make_float3(a.x * b.x, a.y * b.y, a.z * b.z);
}
inline __host__ __device__ float3 operator*(float b, float3 a)
{
    return make_float3(b * a.x, b * a.y, b * a.z);
}
inline __host__ __device__ float3 operator+(float3 a, float3 b)
{
    return make_float3(a.x + b.x, a.y + b.y, a.z + b.z);
}
inline __host__ __device__ float3 operator+(float3 a, float b)
{
    return make_float3(a.x + b, a.y + b, a.z + b);
}
inline __host__ __device__ void operator+=(float3 &a, float3 b)
{
    a.x += b.x; a.y += b.y; a.z += b.z;
}
inline __host__ __device__ int iDivUp(int a, int b)
{
  return (a % b != 0) ? (a / b + 1) : (a / b);
}
inline __host__ __device__ float dot_vector(float3 u, float3 v)
{
    return u.x*v.x + u.y*v.y + u.z*v.z;
}

#endif
